
# 神经网络基础
```python 
# 查看网络结构和参数估计
from torchinfo import summary
summary(pretrained_net, input_size=(1, 3, 224, 224))
```
- 模型构造
```python
# 继承nn.Module
class NestMLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),
                                 nn.Linear(64, 32), nn.ReLU())
        self.linear = nn.Linear(32, 16)

    def forward(self, X):
        return self.linear(self.net(X))

chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())
chimera(X)
```
- 参数管理
	- state_dict()
	- 一次性访问所有参数`print(*[(name, param.shape) for name, param in net.named_parameters()])`
- 自定义层
	- 继承nn.Module或者使用nn.Sequential嵌套定义
	- 可以在forward中自定义一些计算，比如归一化层
- 读写模型权重
	- load_state_dict()读取权重

## 1. 使用Cuda

```python
import torch

# 检查CUDA是否可用
if torch.cuda.is_available():
    device = torch.device("cuda")  # 设置设备为GPU
else:
    device = torch.device("cpu")  # 如果CUDA不可用，则设置设备为CPU

# 将模型移动到GPU
model = YourModel().to(device)

# 将输入数据转换为CUDA张量
input_data = torch.tensor(input_data).to(device)

# 创建CUDA版本的优化器
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# 在训练循环中使用GPU
for epoch in range(num_epochs):
    # 前向传播、损失计算等操作
    output = model(input_data)
    # 反向传播和参数更新
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

```


# 卷积神经网络
*卷积神经网络*（convolutional neural network，CNN）是一类强大的、为处理图像数据而设计的神经网络。
基于卷积神经网络架构的模型在计算机视觉领域中已经占主导地位，当今几乎所有的图像识别、目标检测或语义分割相关的学术竞赛和商业应用都以这种方法为基础。
## 1. Why局部性和平移不变性

- 图像的平移不变性使我们以相同的方式处理局部图像，而不在乎它的位置。
- 局部性意味着计算相应的隐藏表示只需一小部分局部图像像素。
- 在图像处理中，卷积层通常比全连接层需要更少的参数，但依旧获得高效用的模型。
- 卷积神经网络（CNN）是一类特殊的神经网络，它可以包含多个卷积层。
- 多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征。

## 2. What卷积的理解

**一维卷积**，x时刻发生的事件对t时刻事件的影响
f是发生的事件
g是事件影响力衰减曲线
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697529111000re0tak.png)

**图像卷积**
可以理解一个像素点如何对周围的主动试探，f是输入图像，g是试探的模板
应用：特征提取，锐化，边缘检测

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697528975000llik96.png)
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697529029000rj04wa.png)
## 3. 卷积层

### 3.1. **卷积核**
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/16975471610006cfybd.png)

### 3.2. **交叉相关和卷积**
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/16975471980002astuu.png)
### 3.3. **输入输出**
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697547131000mqkm3c.png)

### 3.4. 小结
* 二维卷积层的核心计算是二维互相关运算。最简单的形式是，对二维输入数据和卷积核执行互相关操作，然后添加一个偏置。
* 我们可以设计一个卷积核来检测图像的边缘。
* 我们可以从数据中学习卷积核的参数。
* 学习卷积核时，无论用严格卷积运算或互相关运算，卷积层的输出不会受太大影响。
* 当需要检测输入特征中更广区域时，我们可以构建一个更深的卷积网络。

## 4. 填充和步幅

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697547595000hhctdr.png)
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697607700000ilg4a8.png)

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/16975475600007auuqp.png)

**测试**
```
k=3,padding=1,strides=2
k=5,padding=2,strides=2
为什么是减半？

# 前提是对高宽进行无损填充
# 为什么strides=2时减半，(n-3+2+2)/2，即(n+1)/2所以对偶数是减半
# 当核为5*5时，(n-5+4+2)/2也是(n+1)/2
```

**小结**
* 填充可以增加输出的高度和宽度。这常用来使输出与输入具有相同的高和宽。
* 步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的$1/n$（$n$是一个大于$1$的整数）。
* 填充和步幅可用于有效地调整数据的维度。
* 填充0不会影响模型推理性能，0经过偏移处理后没有影响


## 5. 多通道

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697550177000o7z1gi.png)

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697550200000p38yxh.png)

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/16975505700009mpnvy.png)
### 5.1. 复杂度
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697550594000zmzkqd.png)

### 5.2. 小结
* 多输入多输出通道可以用来扩展卷积层的模型。
* 多输出通道是将X和多层K进行运算得出多个输出
* 当以每像素为基础应用时，$1\times 1$卷积层相当于全连接层。
* $1\times 1$卷积层通常用于调整网络层的通道数量和控制模型复杂性。

## 6. 池化层

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/16976100500005d9g5q.png)


* 对于给定输入元素，最大池化层会输出该窗口内的最大值，平均池化层会输出该窗口内的平均值。
* 池化层的主要优点之一是减轻卷积层对位置的过度敏感。
* 我们可以指定池化层的填充和步幅。
* 使用最大池化层以及大于1的步幅，可减少空间维度（如高度和宽度）。
* 池化层的输出通道数与输入通道数相同。


## 7. LeNet卷积网络

### 7.1. 疑问

- 每次将一小批数据集装入GPU，这导致每次都需要等待，能否预装入数据
- 多轮epoch，每轮的数据是要重新载入吗
- LeNet是将分辨率缩小了，但通道数变多，通道可以看作神经元吗

# 现代卷积神经网络

## 1. AlexNet更大更深
视频时间33分，模型计算复杂度表格
[24 深度卷积神经网络 AlexNet【动手学深度学习v2】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1h54y1L7oe/?spm_id_from=333.788.recommend_more_video.0&vd_source=2bc27ec22a8e739492a12db57107f831)

Alex网络架构
<div style="text-align:center"> <img src="https://zh-v2.d2l.ai/_images/alexnet.svg" alt="img"> </div>
计算复杂度
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697637793000dl2hb8.png)


- AlexNet的架构与LeNet相似，但使用了更多的卷积层和更多的参数来拟合大规模的ImageNet数据集。
- 今天，AlexNet已经被更有效的架构所超越，但它是从浅层网络到深层网络的关键一步。
- 尽管AlexNet的代码只比LeNet多出几行，但学术界花了很多年才接受深度学习这一概念，并应用其出色的实验结果。这也是由于缺乏有效的计算工具。
- Dropout、ReLU和预处理是提升计算机视觉任务性能的其他关键步骤。

## 2. VGG块

![zh-v2.d2l.ai/_images/vgg.svg](https://zh-v2.d2l.ai/_images/vgg.svg)


* VGG-11使用可复用的卷积块构造网络。不同的VGG模型可通过每个块中卷积层数量和输出通道数量的差异来定义。
* 块的使用导致网络定义的非常简洁。使用块可以有效地设计复杂的网络。
* 在VGG论文中，Simonyan和Ziserman尝试了各种架构。特别是他们发现深层且窄的卷积（即$3 \times 3$）比较浅层且宽的卷积更有效。

## 3. NiN多模块

![](https://zh-v2.d2l.ai/_images/nin.svg)

* NiN使用由一个卷积层和多个$1\times 1$卷积层组成的块。该块可以在卷积神经网络中使用，以允许更多的每像素非线性。
* NiN去除了容易造成过拟合的全连接层，将它们替换为全局平均汇聚层（即在所有位置上进行求和）。该汇聚层通道数量为所需的输出数量（例如，Fashion-MNIST的输出为10）。
* 移除全连接层可减少过拟合，同时显著减少NiN的参数。
* NiN的设计影响了许多后续卷积神经网络的设计。、

## 4. GoogleNet并行模块

- 计算量128,049,152，核大小x输入输出通道x图片大小
- 参数量163,328，核大小x输入输出通道
- 计算复杂度显著降低

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697787214000rnlejm.png)


![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697788283000hxf2rh.png)


* Inception块相当于一个有4条路径的子网络。它通过不同窗口形状的卷积层和最大汇聚层来并行抽取信息，并使用$1×1$卷积层减少每像素级别上的通道维数从而降低模型复杂度。
*  GoogLeNet将多个设计精细的Inception块与其他层（卷积层、全连接层）串联起来。其中Inception块的通道数分配之比是在ImageNet数据集上通过大量的实验得来的。
* GoogLeNet和它的后继者们一度是ImageNet上最有效的模型之一：它以较低的计算复杂度提供了类似的测试精度。


## 5. 参数量计算方法
参数量表示了神经网络中需要学习的权重和偏置的总数。

1. 全连接层（Fully Connected Layer）：
全连接层的参数数量取决于输入特征的维度和输出特征的维度。如果输入特征维度为n，输出特征维度为m，则全连接层的参数数量为 (n + 1) * m，其中加1是考虑到了偏置项。

2. 卷积层（Convolutional Layer）：
卷积层的参数数量取决于卷积核的大小、深度以及输入特征图的深度。假设卷积核大小为k×k，输入特征图的深度为d_in，输出特征图的深度为d_out，则卷积层的参数数量为 k * k * d_in * d_out。

3. 循环层（Recurrent Layer）：
循环层（如LSTM或GRU）的参数数量取决于隐藏状态的维度、输入维度和偏置项。假设隐藏状态的维度为h，输入维度为x，则循环层的参数数量为 4 * (h * h + h * x + h)。

4. 池化层（Pooling Layer）和激活函数层（Activation Layer）：
池化层和激活函数层没有需要学习的参数，因此它们不会增加网络的参数量。

要计算整个深度神经网络的参数量，将每个层的参数数量相加即可。请注意，还应该考虑到共享权重和偏置的情况，例如在多个层之间共享参数的情况。
除了参数量，还可以计算模型的浮点运算量（FLOPs）等指标来评估模型的计算复杂度。


## 6. 批量归一化

**和Dropout类似，因为加入了随机扰动，但可以通过加大学习率来提升训练速度**

- 均值和方差是可调整的值，可初始化为（0，1）
- 训练时用每个小批量的均值方差去更新全局均值方差，推理使用全局变量
- gamma和beta是可学习的参数
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697792783000twjujy.png)

## 7. ResNet残差网络
革命性理论
1. 可以将网络的范围缩小在最优解附近，而不是整个网络
2. 下层网络可以通过res路径得到一个较大的梯度，缓解了下层网络梯度消失的问题
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/16978017810008db19a.png)



![](https://zh-v2.d2l.ai/_images/functionclasses.svg)
设f(x)= x + g(x)
假设g(x)是没有实际用处的，可以使得f(x)=x，即跳过没有用的网络块

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697794956000n8nqt2.png)

![](https://zh-v2.d2l.ai/_images/resnet-block.svg)
### 7.1. 小结
* 学习嵌套函数（nested function）是训练神经网络的理想情况。在深层神经网络中，学习另一层作为恒等映射（identity function）较容易（尽管这是一个极端情况）。
* 残差映射可以更容易地学习同一函数，例如将权重层中的参数近似为零。
* 利用残差块（residual blocks）可以训练出一个有效的深层神经网络：输入可以通过层间的残余连接更快地向前传播。
* 残差网络（ResNet）对随后的深层神经网络设计产生了深远影响。


## 8. DesenNet稠密网络

resnet是将结果相加，desenNet是将结果完整保存下来

![](https://zh-v2.d2l.ai/_images/densenet-block.svg)

类似于ResNet使用的4个残差块，DenseNet使用的是4个稠密块。
![](https://zh-v2.d2l.ai/_images/densenet.svg)

为了避免Y变得过于大，需要加入_过渡层_（transition layer）来控制Y的大小
由于每个稠密块都会带来通道数的增加，使用过多则会过于复杂化模型。 而过渡层可以用来控制模型复杂度。 它通过1×1卷积层来**减小通道数**，并使用步幅为2的平均汇聚层**减半高和宽**，从而进一步降低模型复杂度。

# 硬件

## 1. CPU和GPU
![](https://zh-v2.d2l.ai/_images/latencynumbers.png)

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/16978851760004ndv3l.png)



## 2. 计算单元
DSP,NPU,TPU等都是ASIC芯片大类
FPGA可以用于芯片设计评估

![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697885001000l30ufs.png)
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697885013000mecx97.png)
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697885019000ytvrze.png)
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/169788502800096b2l9.png)
![gh](https://cdn.jsdelivr.net/gh/narugakuru/images@master/img/1697885045000fw4dlv.png)

## 3. GPU并行计算
[34 多GPU训练实现【动手学深度学习v2】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1MQ4y1R7Qg/?spm_id_from=trigger_reload&vd_source=2bc27ec22a8e739492a12db57107f831)

- 数据并行
- 模型并行

![](https://zh-v2.d2l.ai/_images/splitting.svg)

