---
title: 文献考核综述Few-Shot Medical Image Segmentation
tags:
  - Survey
  - FSS
date created: 2024-09-28
date modified: 2024-09-29
NotionID-Paper: 110e05f0-ba91-81a6-9ae4-e2b03e4f1648
link-Paper: https://hikari-note.notion.site/Few-Shot-Medical-Image-Segmentation-110e05f0ba9181a69ae4e2b03e4f1648
---

准备好ppt, 包括看了哪个方向哪些文献，目前研究现状，做了哪些实验，下一步看哪些文献或研究计划等

- [Visual Semantic Segmentation Based on Few/Zero-Shot Learning: An Overview](https://arxiv.org/abs/2211.08352)
- [Few-shot learning based on deep learning: A survey](https://www.aimspress.com/article/id/658235b8ba35de05607ed3c6)
- [Few Shot Semantic Segmentation: a review of methodologies, benchmarks, and open challenges (arxiv.org)](https://arxiv.org/html/2304.05832v2)
- Few-shot Medical Image Segmentation with Cycle-resemblance Attention
- Self-Support Few-Shot Semantic Segmentation
- APANet: Adaptive Prototypes Alignment Network for Few-Shot Semantic Segmentation
- MSANet: Multi-Similarity and Attention Guidance for Boosting Few-Shot Segmentation

![](Paper/attachments/Pasted%20image%2020240928152514.png)

# 研究现状

## 1. 背景

少样本语义分割（FSS）是指在给定由有限数量的图像-掩码对组成的Support集的情况下，预测Query图像中目标类别的语义分割掩码的问题。
FSS通常涉及Episodic training和Transfer Learning。情景学习是把数据集分为support和query进行训练和验证。迁移学习是使用一些预训练模型作为特征提取器，骨干网络。
**学术界研究方向**
- **网络架构创新**：探索不同类型神经网络的结合，如卷积神经网络与图神经网络，以实现更优的特征提取和表示能力。
- **数据增强**：通过引入旋转、缩放、颜色变换等技术，增加训练样本的多样性，进而提升模型的泛化能力。
- **特征提取、表征、融合策略**：开发高效的融合方法，以整合多个参数集的特征，增强模型的综合性能。
- **跨任务迁移学习**：研究如何将其他视觉任务的知识有效迁移，以提升少样本语义分割任务的表现。
- **损失函数优化**：构建更为精细的损失函数，以提高模型在特定任务中的性能和收敛效率。

## 2. Networks

### 2.1. Conditional Networks

这类模型包含两个并行分支：条件分支和分割分支。
条件分支 g 接收支持集 Support 作为输入，并生成参数集 θ 。分割分支 h 则接收查询图像 Query 和由条件分支 g 生成的参数集 θ ，以产生预测掩码 M^q 。
特征提取器是预训练的，并在条件分支和分割分支之间共享。
**关键点：模型架构设计，参数集，损失函数和优化策略，特征表示能力**

#### 2.1.1. 关键考量

**条件分支的特征提取能力，分割分支对条件分支特征的利用效率**

1. **模型架构设计** ：
    - **条件分支和分割分支的交互** ：选择合适的条件函数 gg 和分割函数 hh 设计至关重要。它们之间的有效交互如何影响最终的预测精度。
    - **特征提取器的共享与预训练** ：在两个分支之间共享的特征提取器是否经过充分的预训练，以确保提取的特征足够丰富。
2. **参数集的设计** ：
    - **参数类型** ：不同类型的参数集 θθ 可以通过不同的方式影响模型性能，例如参数的选择、如何从支持集中提取特征等。
    - **多样性和互补性** ：如Zhang et al. (2022)所示，利用多个参数集的多样性和互补性来增强特征的丰富性。
3. **损失函数和优化策略** ：
    - **损失函数的设计** ：选择合适的损失函数，尤其是在训练分割分支时，可以显著影响分割结果。
    - **优化算法** ：使用合适的优化算法和学习率策略，以确保模型收敛并避免过拟合。
4. **特征表达能力** ：
    - **特征表示的质量** ：特征体积 FqFq​ 的表示能力对于分割任务至关重要，选择合适的嵌入函数 ϕϕ 来提取关键特征。
5. **注意力机制** ：
    - **自注意力机制** ：在条件网络中引入自注意力机制可以让模型更有效地聚焦于重要特征区域，从而提升分割性能。

#### 2.1.2. 优化方向

1. **网络架构创新** ：
    - 考虑新的网络架构，例如结合卷积神经网络和图神经网络，以更好地处理空间和关系信息。
2. **自适应学习** ：
    - 引入自适应机制，让模型根据输入图像的内容动态调整参数集 θθ。如Zhang et al.的自适应嵌入可以进一步扩展。
3. **样本多样性增强** ：
    - 通过数据增强技术（例如旋转、缩放，颜色变换等）来增强训练集的多样性，提高模型的泛化能力。
4. **调制与融合策略** ：
    - 在多个参数集之间采用更为有效的融合策略，将各类特征的贡献进行调制，提升整体模型效果。
5. **跨任务迁移学习** ：
    - 可以探索如何通过跨任务模型的迁移学习来提升FSS任务的性能，例如借用已有的在其他视觉任务（如目标检测、图像分类）中表现良好的网络。

### 2.2. Prototypical Networks

原型网络基于这样一种理论：图像可以在某个嵌入空间中表示为点，其中相似对象的图像由相邻的点表示，而远离的点则表示不同对象的图像。因此，计算支持集中与同一类图像相关联的所有点的质心，将得到该类的一个原型点。

#### 2.2.1. 关键考量

在这一解决方案家族中，设计具有代表性的原型并采用可靠的距离度量标准以实现正确的标签分配至关重要。**关键考量基于两个基本设计选择：原型的计算与合适距离度量标准的选取。**

1. 一种广泛采用的原型生成方法是应用掩码平均池化（MAP）
2. 第二个关键设计选择涉及选取适当的距离度量来衡量原型与查询特征之间的相似性。余弦距离度量相比欧几里得距离提供了更高的稳定性和优越的性能，认为余弦相似性的有界特性使其更适合优化，从而在后续研究中受到青睐

#### 2.2.2. 优化方向

原型提炼，自监督学习机制，模型框架，类增保持基类性能，实验环境优化
1. **原型的计算方法** ：
    - **掩码平均池化（MAP）** ：这种方法有效整合了图像区域的重要信息，有助于提高原型的表示能力。但可以研究如何进一步改进池化策略，例如自适应池化或引入注意力机制来提升重要特征的权重。
2. **距离度量标准** ：
    - **余弦距离与欧几里得距离** ：选择合适的距离度量方法对模型性能影响显著。研究可以聚焦于开发更复杂的距离度量，比如在原型之间动态计算的加权距离，或者基于学习的距离度量。
3. **类间与类内变异** ：
    - 当前方法在处理类内变异时可能遇到挑战。优化方向可以是设计更为复杂的嵌入网络，或者引入生成模型以更好地模拟不同类的变异特征。
4. **原型的更新策略** ：
    - 在传统方法中，原型通常在训练阶段固定。研究可以探讨在测试阶段对原型进行动态调整，比如通过增量学习方法更新原型位置。

## 3. Latent Space Optimization

### 3.1. Generative Models

生成模型在少样本语义分割（FSS）中扮演着关键角色，通过学习数据的潜在分布，以生成新样本来增强支持集的多样性。研究表明，使用生成对抗网络（GANs）或变分自编码器（VAEs）能够有效地生成具有代表性的伪样本，从而提高模型的泛化能力。此外，生成模型在特征空间中的优化可以帮助更好地捕捉类别间的变异，提高分割精度。

### 3.2. Contrastive Learning

对比学习作为一种无监督学习策略，能够通过最大化相似样本间的相似性与最小化不相似样本间的相似性来优化潜在空间。这一方法在FSS任务中表现出色，尤其是在支持集样本稀缺的情况下。通过构建正负样本对，对比学习可以有效提升特征的判别能力，从而促进更精确的分割效果。未来的研究可集中在对比损失函数的优化及其与传统损失函数的结合使用。

### 3.3. Variational Auto Encoders

变分自编码器（VAEs）通过引入潜在变量来建模数据分布，促进了潜在空间的优化。VAEs在FSS中提供了一种有效的特征学习方式，其生成的潜在表示不仅保留了数据的结构信息，还为生成新样本提供了基础。通过改进潜在空间的重参数化技巧，可以进一步提升模型对稀缺样本的适应能力和生成能力。

### 3.4. Prompt Engineering

在近年来的研究中，提示工程（Prompt Engineering）被广泛应用于多种任务，尤其是在预训练语言模型中。通过为模型提供特定的提示信息，能够引导模型关注目标特征。在FSS中，设计有效的提示可以帮助模型在潜在空间中更好地聚焦于关键区域，从而优化分割结果。未来研究可探讨如何动态生成和调整提示，以适应不同类别和样本特征。

### 3.5. Generalist Models

通用模型的设计旨在通过共享知识和特征，提升模型在多种任务上的表现。在FSS中，通用模型能够通过跨任务的知识迁移来增强模型的能力，尤其是在类别不均衡和样本稀缺的情况下。未来的研究方向应关注于如何优化通用模型架构，使其在特定任务上保持高效性与灵活性，同时探索不同任务间的特征共享策略。

# 实验

### DSPNet

![](Paper/attachments/Pasted%20image%2020240928171744.png)
