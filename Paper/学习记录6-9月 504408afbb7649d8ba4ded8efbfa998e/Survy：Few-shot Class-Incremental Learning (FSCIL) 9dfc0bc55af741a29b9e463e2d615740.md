---
tags:
  - FSCIL
  - FSS
---
# Survy：Few-shot Class-Incremental Learning (FSCIL)

Owner: hikari

## 概要

这篇论文是关于"Few-shot Class-Incremental Learning (FSCIL)"的综述，即小样本增量学习。它探讨了机器学习中的一项独特挑战：在不遗忘先前知识的同时，从有限的标记样本中学习新类别的增量学习。以下是对论文内容的总结：

**摘要**：论文提供了FSCIL领域的全面和系统性回顾。作者深入探讨了FSCIL的多个方面，包括问题定义、主要挑战（不可靠的经验风险最小化和稳定性-可塑性困境）、通用方案、与增量学习（IL）和少样本学习（FSL）相关问题的讨论。此外，还提供了基准数据集和评估指标的概览，并介绍了基于数据、结构和优化方法的FSCIL分类方法，以及基于锚点和非锚点方法的FSCIL目标检测方法。最后，论文提出了几个值得进一步研究的有前景的研究方向。

**1. 引言**：介绍了深度神经网络（DNNs）的发展阶段，并指出了它们在静态任务中的局限性，尤其是在面对新任务或数据分布变化时，需要从头开始训练，导致计算和存储成本增加。

**2. 背景**：

- **问题定义**：FSCIL旨在学习一个机器学习模型，该模型能够从新类别的少量标记训练样本中连续学习知识，同时保留先前类别的知识。
- **核心挑战**：包括经验风险最小化的不可靠性和稳定性-可塑性困境。
- **通用方案**：介绍了两种主要的FSCIL框架，包括特征提取器+softmax分类器和特征嵌入网络+最近类均值分类器。
- **相关问题**：讨论了FSCIL与其他增量学习场景（如CIL、TIL和DIL）的关系和区别。

**3. 数据集和评估**：

- 讨论了FSCIL中用于分类和目标检测任务的主要公共数据集，包括miniImageNet、CIFAR-100、CUB-200、COCO和PASCAL VOC。
- 介绍了用于分类和目标检测任务的评估指标，如分类准确率、平均准确率（AA）、性能下降率（PD）、平均精度（AP）和平均召回率（AR）。

**4. 小样本增量分类**：

- 总结了现有的FSCIL分类方法，并将它们分为基于数据、结构和优化方法三类。
- 讨论了数据重放、伪场景构建、动态结构方法、注意力机制和知识蒸馏等策略。

**5. 小样本增量目标检测**：

- 讨论了与分类任务不同的地方，目标检测任务需要同时学习新类别的对象定位和分类。
- 总结了基于锚点和非锚点框架的方法。

**6. 结论和展望**：

- 提供了对FSCIL领域的全面回顾，并讨论了潜在的研究方向，如缩小人机差距、实际设置、知识获取与更新、应用和安全性等。

**作者信息**：论文列出了作者的背景和研究兴趣，包括在计算机视觉、深度学习、模式识别和机器学习领域的贡献。

整体来看，这篇论文为FSCIL领域提供了一个系统的框架，并指出了当前的挑战和未来的研究方向。

## 传统方法的局限性

能力和应用局限性：这些系统是针对特定任务进行优化的，它们已经接受过培训，这使得它们不适合动态情况。

数据驱动的差距：与人类不同，人类只需要很少的例子就能有效地学习，并表现出终身的适应能力。事实上，这些系统严重依赖于大量的数据，缺乏人类学习所固有的多功能性和保留性。

效率和可持续性问题：这些数据和能源密集型系统需要频繁地重新培训新数据或任务，增加了计算资源压力和碳足迹。

隐私和安全问题：动态世界使这些系统在新的场景中面临更高的安全风险。此外，保留会增加数据泄露的风险，引发隐私警报。

IL，也称为持续或终身学习，使系统能够随着时间的推移学习新任务，同时保持以前的知识[5，6，7]，旨在复制人类的学习能力[5]。类增量学习（CIL）是非常突出的，它解决了现实世界中的关键挑战，模型应该适应新的类，而不会忘记现有的类。

## FewShot CIL

适应动态世界：FSCIL使模型能够获取新的类，同时保留以前的知识，这是有效适应动态变化世界的关键能力。

·高数据效率：FSCIL可以减少大量样品标记的必要性，在数据有限和标记成本高的情况下提供优势。

·环境可持续性：FSCIL通过比传统方法需要更少的计算和存储资源来促进可持续性，这在资源有限的环境中是一个至关重要的优势。

·数据安全和隐私：FSCIL减少了保留大量历史数据的需求，从而符合数据安全和隐私要求。·多功能应用：FSCIL适用于各种领域，特别是在数据有限，标签成本高，需要频繁更新类别的情况下

FSCIL面临重大挑战，特别是不可靠的经验风险最小化和稳定性-可塑性困境。在FSCIL会话中，有限的监督数据意味着经验风险无法准确地表示预期风险，降低了模型的泛化能力，增加了过拟合风险。此外，随着新课程的不断增加，旧知识很容易被新知识遗忘和覆盖。这导致了灾难性的遗忘。否则，可能会出现不妥协。因此，平衡模型稳定性和可塑性是另一个核心挑战。

## 两类CIL框架

在论文中，针对Few-shot Class-Incremental Learning (FSCIL)，提出了两种主要的框架来应对学习新类别同时保留旧类别知识的挑战。以下是对这两种框架的详细描述：

1. **特征提取器 + Softmax分类器 (Feature Extractor + Softmax Classifier)**:
    - 这个框架包含一个特征提取器和一个softmax分类器。特征提取器用于从输入数据中提取特征，而softmax分类器则基于这些特征对数据进行分类。
    - 在增量学习过程中，整个网络（包括特征提取器和分类器）都是可训练的。这允许模型在新会话中学习新类别时，能够调整和优化整个网络的参数。
    - 为了对抗灾难性遗忘（catastrophic forgetting），一些研究采用了知识蒸馏（Knowledge Distillation, KD）技术来训练模型。知识蒸馏允许模型在保持对旧类别的分类能力的同时，适应新类别。
2. **特征嵌入网络 + 最近类均值分类器 (Feature Embedding + Nearest Mean Classifier)**:
    - 这个框架专注于训练一个特征嵌入网络，该网络将样本映射到特征空间中，其中样本之间的距离代表了语义差异。
    - 特征嵌入网络在基础训练后通常是固定的，不会在增量学习过程中进行调整。分类是通过最近类均值（Nearest Class Mean, NCM）分类器来完成的，该分类器根据特征空间中的距离来确定样本的类别。
    - 例如，一些研究使用度量损失（metric loss）来训练嵌入网络，使其能够学习更具辨别性的特征，并且更好地适应增量类别。

这两种框架的主要区别在于它们如何处理特征提取和分类，以及它们在增量学习过程中如何调整模型参数。第一种框架允许在整个学习过程中对所有参数进行优化，而第二种框架则侧重于学习一个稳定的特征表示，然后使用这个表示来进行分类，减少了对整个网络的调整需求。

论文还提到了一些特定的方法和策略，例如数据重放（data replay）和伪场景构建（pseudo-scenarios construction），这些方法旨在提高模型在面对新类别时的泛化能力和减少对旧知识的遗忘。这些策略可以应用于上述任何一种框架，以增强模型在FSCIL任务中的表现。

## 小样本基于增量分类

小样本增量分类（Few-shot Class-Incremental Classification, FSCIC）是FSCIL领域中的一个重要任务，它要求模型在面对新类别时，只能使用非常有限的标记样本进行学习，同时还要保留对之前学习过类别的知识。以下是对FSCIC的详细讨论：

### 核心问题

- **有限样本学习**：每个新类别只有少量的标记样本，这要求模型能够快速学习并泛化到新情况。
- **增量学习**：模型需要在不断到来的新数据上进行学习，而不是一次性学习所有数据。
- **灾难性遗忘**：在学习新类别的过程中，模型可能会遗忘之前学习过的类别，这是需要避免的。

### 方法分类

FSCIC的方法可以从不同的角度进行分类，论文中主要从以下三个角度进行了分类：

1. **基于数据的方法 (Data-based Approaches)**：
    - **数据重放 (Data Replay)**：存储之前会话的一部分原始样本，并在新会话中重放这些样本，以减轻灾难性遗忘。
    - **生成式重放 (Generative Replay)**：使用生成模型（如GAN）生成旧类别的样本或特征表示，并在新会话中使用这些生成的数据。
2. **基于结构的方法 (Structure-based Approaches)**：
    - **动态结构 (Dynamic Structure)**：动态调整模型结构或原型之间的关系，以适应新类别的学习。
    - **图基方法 (Graph-based Methods)**：使用图结构来描述不同类别之间的相似性或相关性，并根据类别之间的相互影响调整图结构。
3. **基于优化的方法 (Optimization-based Approaches)**：
    - **表示学习 (Representation Learning)**：通过有效的特征表示学习，使模型能够在少量样本中识别和利用潜在的模式。
    - **度量学习 (Metric Learning)**：确定对象之间相似性的最优距离度量，以提高学习任务的性能。
    - **特征空间方法 (Feature Space-based Methods)**：优化特征空间以学习更健壮和高效的特征表示。
    - **特征融合 (Feature Fusion)**：整合来自不同信息源或特征提取方法的特征，以创建更全面和有效的表示。
4. **知识蒸馏 (Knowledge Distillation, KD)**：
    - 使用KD技术将旧模型（教师模型）的知识传递给新模型（学生模型），以解决灾难性遗忘问题。
5. **元学习 (Meta Learning)**：
    - 利用从多个学习过程中提取的经验来增强模型对未来任务的适应能力。

## **小样本增量目标检测FSCIOD**

### 任务区别

与分类任务不同，FSCIOD不仅要求模型识别新类别，还要求对图像中每个对应个体对象进行准确的定位（使用边界框回归或分割），并且对它们进行分类。这意味着模型需要同时处理分类和定位任务。

### 方法分类

FSCIOD的方法可以从两个主要角度进行分类：基于锚点的方法（Anchor-based）和不基于锚点的方法（Anchor-free）。

1. **基于锚点的方法 (Anchor-based Approaches)**：
    - 这些方法通常使用Mask R-CNN作为基础框架，它是一个两阶段的检测框架，结合了对象检测和像素级分割。
    - 例如，iMTFA框架通过添加一个与Mask R-CNN相似的实例分割分支来处理FSCIL中的实例分割任务。
2. **不基于锚点的方法 (Anchor-free Approaches)**：
    - 这些方法不需要预先定义锚点框，可以更灵活地处理新类别。
    - 包括基于CentreNet、FCOS（Fully Convolutional One-Stage Object Detection）和DETR（Detection Transformer）等框架的方法。

### 核心挑战

- **有限样本学习**：每个新类别的样本数量有限，这要求模型能够快速适应并准确检测新对象。
- **增量学习**：模型需要在不断到来的新数据上进行学习，同时保留对旧类别的检测能力。
- **灾难性遗忘**：在学习新类别的同时，模型可能会遗忘旧类别的检测知识。

### 评估指标

- **平均精度 (Average Precision, AP)**：评估模型对新类别和旧类别的检测性能。
- **平均召回率 (Average Recall, AR)**：评估模型对新类别和旧类别的检测完整性。
- **AP50**：在50%的召回率下的平均精度，是一个常用的辅助指标。

### 研究进展

- 尽管FSCIOD是一个相对较新的研究领域，但已有一些研究探索了不同的方法来提高模型在增量学习环境中的性能。
- 一些研究通过引入元学习、自监督学习或知识蒸馏等技术来提高模型对新类别的适应能力和减少对旧知识的遗忘。

### 未来方向

- **更复杂的场景适应性**：研究模型在更复杂、更动态的环境中的适应性和鲁棒性。
- **跨领域学习**：提高模型在不同领域（如不同的成像条件和环境）中的泛化能力。
- **隐私和安全性**：考虑在处理涉及个人隐私数据的任务时，如何保护数据隐私并确保模型的安全性。