
### 引言

1. 你当前正在编写的代码的哪些部分可以“学习”，即通过学习和⾃动确定代码中所做的设计选择来改进？你的代码是否包含启发式设计选择
  ```
绝大多数规则与启发式的都可以用来学习，例如：图片分类、垃圾分类。涉及到梯度下降算法的代码都涉及到学习的过程，因为需要不断优化参数，启发式设计就是一个不断探索并接近答案的过程，毫无疑问是涉及的
```
2. 你遇到的哪些问题有许多解决它们的样本，但没有具体的⾃动化⽅法？这些可能是使⽤深度学习的主要候选者
```
比如水下去噪，学术界会有一些数据集可以直接处理这些问题，自动化的方法我想可能是爬虫类似这样的，或者说是自动流水线上的设备指标实时上传。
```
3. 如果把⼈⼯智能的发展看作⼀场新的⼯业⾰命，那么算法和数据之间的关系是什么？它类似于蒸汽机和煤吗？根本区别是什么？
```
在2021年吴恩达提出基于数据的深度学习无疑回答了这个问题，煤是数据，模型是蒸汽机，根本的区别是就是煤和蒸汽机的关系。数据作为蒸汽机的燃料产生了动力（生产力）。
```
4. 你还可以在哪⾥应⽤端到端的训练⽅法，⽐如 图1.1.2 、物理、⼯程和计量经济学？
```
工程我想测距可能会有end2end的操作吧
```



# 线性模型

### 线性代数
### 练习

1. 证明一个矩阵$\mathbf{A}$的转置的转置是$\mathbf{A}$，即$(\mathbf{A}^\top)^\top = \mathbf{A}$。
pass

2. 给出两个矩阵$\mathbf{A}$和$\mathbf{B}$，证明“它们转置的和”等于“它们和的转置”，即$\mathbf{A}^\top + \mathbf{B}^\top = (\mathbf{A} + \mathbf{B})^\top$。
pass

3. 给定任意方阵$\mathbf{A}$，$\mathbf{A} + \mathbf{A}^\top$总是对称的吗?为什么?
pass

4. 本节中定义了形状$(2,3,4)$的张量`X`。`len(X)`的输出结果是什么？
```
2
```

5. 对于任意形状的张量`X`,`len(X)`是否总是对应于`X`特定轴的长度?这个轴是什么?
```
len总是以0轴作为标准计算长度
```

6. 运行`A/A.sum(axis=1)`，看看会发生什么。请分析一下原因？
```python
A = torch.arange(24).reshape(6,4)
RuntimeError: The size of tensor a (4) must match the size of tensor b (6) at non-singleton dimension 1
# 因为两个张量的维度不同，而且无法进行广播,需要对A.sum(axis=1)进行reshape
C = A.sum(axis=1).reshape(6,1)
A / C
```

7. 考虑一个具有形状$(2,3,4)$的张量，在轴0、1、2上的求和输出是什么形状?
```
(3,4),(2,4),(2,3)
```

8. 为`linalg.norm`函数提供3个或更多轴的张量，并观察其输出。对于任意形状的张量这个函数计算得到什么?
```
一个Frobenius 范数
```


### 线性回归

1. 如果我们将权重初始化为零，会发生什么。算法仍然有效吗？
```
   什么都不会发生，无效
```

2. 假设试图为电压和电流的关系建立一个模型。自动微分可以用来学习模型的参数吗?
```
   UI=W，I^2R=U
```

3. 能基于[普朗克定律](https://en.wikipedia.org/wiki/Planck%27s_law)使用光谱能量密度来确定物体的温度吗？
```
   ?
```

4. 计算二阶导数时可能会遇到什么问题？这些问题可以如何解决？
```
   导数可能不存在，可能收敛过快
```

5. 为什么在`squared_loss`函数中需要使用`reshape`函数？
```
   保证shape一致
```

6. 尝试使用不同的学习率，观察损失函数值下降的快慢。
```
   合理范围内，学习率的大小基本和快慢正相关。超出一定范围会导致步长过大
```

7. 如果样本个数不能被批量大小整除，`data_iter`函数的行为会有什么变化？
```
   最后会返回一个余数
```

### Softmax

### 问题
1. 本节直接实现了基于数学定义softmax运算的softmax函数。这可能会导致什么问题？提示：尝试计

算exp(50)的大小。

2. 本节中的函数cross_entropy是根据交叉熵损失函数的定义实现的。它可能有什么问题？提示：考虑对

数的定义域。

3. 请想一个解决方案来解决上述两个问题。

4. 返回概率最大的分类标签总是最优解吗？例如，医疗诊断场景下可以这样做吗？

1. 假设我们使用softmax回归来预测下一个单词，可选取的单词数目过多可能会带来哪些问题?


# 多层感知机

### 激活函数
1. 计算pReLU激活函数的导数。
2. 证明一个仅使用ReLU（或pReLU）的多层感知机构造了一个连续的分段线性函数。
3. 证明tanh(x) + 1 = 2 sigmoid(2x)。
4. 假设我们有一个非线性单元，将它一次应用于一个小批量的数据。这会导致什么样的问题？

### 手动实现MLP
1. 在所有其他参数保持不变的情况下，更改超参数`num_hiddens`的值，并查看此超参数的变化对结果有何影响。确定此超参数的最佳值。
2. 尝试添加更多的隐藏层，并查看它对结果有何影响。
3. 改变学习速率会如何影响结果？保持模型架构和其他超参数（包括轮数）不变，学习率设置为多少会带来最好的结果？
4. 通过对所有超参数（学习率、轮数、隐藏层数、每层的隐藏单元数）进行联合优化，可以得到的最佳结果是什么？
5. 描述为什么涉及多个超参数更具挑战性。
6. 如果想要构建多个超参数的搜索方法，请想出一个聪明的策略。

### MLP
1. 尝试添加不同数量的隐藏层（也可以修改学习率），怎么样设置效果最好？
2. 尝试不同的激活函数，哪个效果最好？
3. 尝试不同的方案来初始化权重，什么方法效果最好？

