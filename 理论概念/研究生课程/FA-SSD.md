---
tags:
  - CV
---

# Small Object Detection using Context and Attention

arXiv:1912.06319v2 [cs.CV] 16 Dec 2019
2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC) by IEEE

# 摘要

在各种环境下应用目标检测算法存在许多局限性。 特别是检测小物体仍然具有挑战性，因为它们具有低分 辨率和有限的信息。为了提高检测小物体的精度，我们提 出了一种使用上下文的物体检测方法。所提出的方法通 过集中多尺度特征，使用来自不同层的附加特征作为上 下文。我们还提出了具有注意力机制的目标检测，该机制 可以关注图像中的对象，并且可以包含来自目标层的上下 文信息。实验结果表明，该方法在小目标检测上也比传统 的SSD具有更高的精度。此外，对于300×300输入，我们在 PAS-CAL VOC2007测试集上实现了78.1%的平均精度 (mAP)。

# 1. 简介

目标检测是计算机视觉中的关键主题之一，其目标 是在给定图像中找到对象的边界框并对其进行分类。近 年来，在深度学习技术的引领下，精度和速度都有了巨 大的提高:更快的R-CNN[13]实现了73.2%的mAP, YOLOv2[12]实现了76.8%的mAP, SSD[10]实现了77.5% 的mAP。然而，在检测小物体方面仍然存在重要的挑战。 例如，SSD在小对象目标上只能实现20.7%的mAP。图1 为SSD无法检测到小对象的故障案例。在小物体检测方 面还有很大的提升空间。

小目标检测难度大是因为低分辨率和有限的像素。例如，如果只看图2上的物体， 人类甚至很难识别出物体。然而，考虑到物体位于天空 的上下文，就可以将其识别为鸟。因此，我们认为解决 这个问题的关键取决于我们如何将上下文作为额外的信 息来帮助检测小物体。

在本文中，我们提出使用上下文信息对象来解决检 测小物体这一具有挑战性的问题。首先，为了提供关于 小对象的足够信息，我们通过利用来自更高层次的对象 上下文的更抽象特征，从小对象的周围像素中提取上下 文信息。通过连接小物体的特征和上下文的特征，我们 增强了小物体的信息，以便检测器能够更好地检测到物 体。其次，为了专注于小物体，我们在早期层使用了注 意机制。这也有助于减少来自背景的不必要的浅层特征 信息。我们在实验中选择单镜头多盒探测器(SSD)[10] 作为我们的基线。然而，这个想法可以推广到其他网络。 为了评估所提出的模型的性能，我们将我们的模型训练 到PASCAL VOC2007和VOC2012[1]，并与基线和最先进的VOC2007方法进 行比较。

# 2. 相关作品

深度学习的目标检测深度学习技术的进步极大地提 高了目标检测的准确率。第一次使用深度学习进行目标 检测的尝试是R-CNN[4]。R-CNN对使用选择性搜索[16] 生成的区域建议使用卷积神经网络(CNN)。然而，对于 实时应用来说，它太慢了，因为每个提议的区域都要依 次经过cnn。快速R-CNN[3]比R-CNN更快，因为它对所 有的区域建议只执行一次特征提取阶段。但这两个作品 仍然使用单独的阶段进行区域提议，这成为Faster RCNN[13]的主要解决点，[13]将区域提议阶段和分类阶 段结合到一个模型中，从而允许所谓的端到端学习。目 标检测技术甚至被YOLO[11]和SSD[10]加速，显示出足 够高的性能进行实时目标检测。然而，对于小物体，它 们仍然没有表现出良好的性能。 最近，人们提出了几种检测小物体的思路[10,2,7,8]。 Liu等人[10]通过减小大对象的大小来增强小对象数据， 以克服数据不足的问题。除了数据增强的方法，还有一 些在不增加数据集本身的情况下增加所需信息的努力。 DSSD[2]对SSD的所有特征映射应用去卷积技术，得到 缩放后的特征映射。然而，由于对所有特征图应用反卷 积模块，它具有增加模型复杂性和降低速度的局限性。 R-SSD[7]通过池化和反褶积结

合了不同尺度的特征，获得了比DSSD更高的精度和速 度。Li等[8]使用生成式对抗网络(GAN)[5]将低分辨率特 征作为GAN的输入来生成高分辨率特征。 视觉注意网络深度学习中的注意机制可以广义地理 解为专注于解决特定任务的部分输入，而不是看到整个 输入。因此，注意机制与人类在看到或听到某些东西时 所做的事情非常相似，Xu等人[18]使用视觉注意来生成 图像字幕。为了生成与图像对应的标题，他们使用了长 短期记忆(LSTM)， LSTM取给定图像的相关部分。 Sharm等人[14]应用注意机制来识别视频中的动作。 Wang等[17]通过叠加剩余注意模块，提高了ImageNet数 据集上的分类性能。

# 3. 方法

本节将讨论基准SSD，然后是我们提出的提高小对 象检测能力的组件。首先，将SSD与特征融合获取上下 文信息，命名为F-SSD。二是SSD带有关注模块，以给 予网络关注重要部件的能力，命名为A-SSD。第三，我 们将特征融合和注意力模块相结合，命名为FA-SSD。

### 3.1. 单镜头多盒探测器(SSD)

在本节中，我们回顾了单镜头多盒探测器(SSD)[10]， 我们将提高对小物体的检测能力。与YOLO[11]一样， 它是一种单级检测器，其目的是提高速度，同时通过处 理不同级别的特征映射来提高不同尺度下的检测效果， 如图3a所示。这个想法是利用早期特征图的高分辨率来 检测较小的物体，而具有较低分辨率的更深的特征用于 较大的物体检测。 它基于VGG16[15]骨干网和附加层来创建不同分辨 率的特征图，如图3a所示。从每个特征中，再加上一个 额外的卷积层来匹配输出通道，网络预测出由边界框回 归和对象分类组成的输出。 然而，在小对象上的性能仍然很低，VOC 2007年 为20.7%，因此仍有很多改进的空间。我们认为主要有 两个原因。第一，缺乏检测小物体的上下文信息。最重 要的是，用于小物体检测的特征是从缺乏语义信息的浅 层特征中提取的。我们的目标是通过添加特征融合来解 决这两个问题，从而改进SSD。另外，为了改进得更多， 我们增加了注意力模块，让网络只关注重要的部分。

### 3.2. F-SSD:基于上下文特征融合的SSD

为了为我们想要检测对象的给定特征映射(目标-获取特 征)提供上下文，我们将其与来自目标特征层的更高层的特 征映射(上下文特征)融合。例如，在SSD中，给定我们的目 标特征来自conv4_3，我们的上下文特征来自两个层，它们 是conv7和conv8_2，如图3.2所示。虽然我们的特征融合可以 一般化 到任何目标特征和它的任何高级特征。然而，这些特征映射 具有不同的空间大小，因此我们提出如图4所示的融合方法。 在通过连接特征进行融合之前，我们对上下文特征进行反卷 积，使它们具有相同的空间大小带有目标特征的。我们设置上下文特征通道 到目标特征的一半，这样上下文信息的数量就不会压倒目标 特征本身。仅对于F-SSD，我们还为目标特征添加了一个额 外的卷积层，这不会改变通道的空间大小和数量。此外，在对于特征，归一化步骤非常重要，因为不同层的每个 特征值都有不同的尺度。因此，我们在每一层之后执 行批归一化和ReLU。最后，我们通过叠加特征来连接 目标特征和上下文特征。

### 3.3. A-SSD:带关注模块的SSD

视觉注意机制允许专注于图像的一部分，而不是 看到整个区域。受Wang等人[17]提出的剩余注意模块 成功的启发，我们采用剩余注意模块进行对象检测。 对于我们的A-SSD(图3.3)，我们在conv4_3和conv7之后 放置了两阶段剩余注意力模块。尽管它可以推广到任 何一层。每个剩余注意阶段都可以在图5中描述。它由 主干分支和掩模分支组成。主干分支有两个残差块， 每个残差块有3个卷积层，如图5d所示。mask分支通过 执行带有残余连接的下采样和上采样来输出注意图(图 5b为第一阶段，图5c为第二阶段)，然后以s形激活完成。 残差连接使得下采样阶段的特征得以维持。然后将来 自掩码分支的注意映射与主干分支的输出相乘，产生 被关注的特征。最后，参与特征之后是另一个残差块， L2归一化和ReLU。

### 3.4. FA-SSD:结合SSD的特性融合和关注

我们提出了连接3.2节和3.3节中提出的两个特征的 方法，它可以考虑来自目标层和不同层的上下文信息。 与F-SSD相比，我们不是在目标特征上执行一个卷积层， 而是放置一个阶段关注模块，如图3d所示。特征融合 的方法(图4)是一样的。

# 4. 实验

### 4.1. 实验设置

我们将该方法应用于具有相同增广1的SSD[10]。除 非另有说明，否则我们使用带有VGG16骨干网和300 × 300输入的SSD。对于FA-SSD，我们将特征融合方法应 用于SSD的conv4_3和conv7。以conv4_3为目标，使用 conv7和conv8_2作为上下文层，以conv7为目标，使用 conv8_2和conv9_2作为上下文层。我们在较低的2层上 应用注意力模块来检测小目标。注意模块的输出与目 标特征大小相等。我们用PASCAL来训练我们的模型

VOC2007和VOC2012训练数据集，在前80k次迭代时学 习率为10−3 ，在100k和120k次迭代时学习率分别降至10− 4和10−5，批大小为16。所有的测试结果都使用 VOC2007测试数据集进行测试，我们按照COCO[9]进 行目标尺寸分类，其中小目标面积小于32_32，大目标 面积大于96_96。我们使用PyTorch和Titan Xp机器进行 训练和测试。

### 4.2. 消融研究

为了测试各特征融合和关注组件与SSD基线的重要 性，我们比较了SSD、F-SSD、A-SSD和FA-SSD的性 能。表1显示所有F-SSD、A-SSD都优于SSD，这意味 着每个组件都提高了基线。虽然FA-SSD结合融合和关 注的整体性能不如F-SSD，但在小目标检测上，FASSD性能最好，提升显著。

### 4.3. 推理时间

从表1的结果来看，一个有趣的现象是，组件越多， 速度并不总是越慢。这促使我们更详细地查看推理时 间。检测中的推理时间分为两部分，网络推理和包括 非最大抑制(NMS)的后处理。从表2可以看出，虽然 SSD的转发时间最快，但在后处理过程中是最慢的，所 以总的来说，它仍然比F-SSD和A-SSD慢。

### 4.4. 定性结果

图7定性地展示了SSD和FA-SSD的比较，其中FA-SSD 成功时，SSD检测小对象失败。

### 4.5. 注意力可视化

为了对注意力模块有更多的了解，我们将FA-SSD的 注意力掩码可视化。注意掩码取自图5a上的sigmoid函数之 后。注意掩模上有很多通道，512个通道来自conv4_3, 1024个通道来自conv7。每个通道关注的是不同的事物， 既有对象，也有上下文。我们可视化了一些仅遵循VGG口罩见图8。

### 4.6. ResNet骨干网泛化

为了了解不同SSD骨干的泛化，我们对ResNet[6]架构 SSD)进行了实验，特别是ResNet18, ResNet34和ResNet50。为了 使特征大小与原始VGG16骨干网的SSD相同，我们从第二 层结果中提取特征(图6a)。然后是F-SSD(图6b)、A-SSD(图 6c)和FA-SSD(图6c)。 G16主干版本的注意力示例。从表3中可以看出，除了 ResNet34骨干网版本在小对象上的性能不是最好外，其他 版本都遵循表1中VGG16骨干网版本的趋势。

### 4.7. VOC2007检测结果

为了与其他作品进行比较，我们在表4中进行了比较。 所比较的方法均使用VOC2007和VOC2012训练数据集进行 训练。虽然我们的性能比DSSD[2]低，但我们的方法运行 在30 FPS上，而DSSD运行在12 FPS上。

# 5. 结论

在本文中，为了提高检测小物体的准确性，我们提出 了添加上下文感知的方法
通过融合多尺度特征在不同层上显示，并应用注意机制 在目标层上显示。我们的实验表明，与传统SSD相比，目 标检测精度得到了提高，特别是对小目标的检测精度得 到了显著提高。
